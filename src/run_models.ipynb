{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 11:11:49.410208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-13 11:11:50.598710: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-11.7/lib64:\n",
      "2023-02-13 11:11:50.598784: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-11.7/lib64:\n",
      "2023-02-13 11:11:50.598790: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "import warnings\n",
    "from hparams import *\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from models import  *\n",
    "from utils import train_model,set_seeds,create_dataset_from_file\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.metrics import mean_absolute_error\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "set_seeds(42)\n",
    "warnings.filterwarnings('ignore')\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" # 1 for run in gpu -1 for run in cpu\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# os.environ['TF_GPU_ALLOCATOR'] ='cuda_malloc_async' \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataframes\n",
    "train_df = pd.read_csv('../data/Bone Age Training Set/train.csv')\n",
    "df_test = pd.read_excel('../data/Bone Age Test Set/test.xlsx')\n",
    "\n",
    "#appending file extension to id column for both training and testing dataframes\n",
    "train_df['id'] = train_df['id'].apply(lambda x: str(x)+'.png')\n",
    "df_test['Case ID'] = df_test['Case ID'].apply(lambda x: str(x)+'.png') \n",
    "df_test.rename(columns={'Ground truth bone age (months)': 'boneage','Sex':'gender'}, inplace=True)\n",
    "\n",
    "train_df['img_path'] = train_df['id'].apply(lambda x: '../data/Bone Age Training Set/boneage-training-dataset/'+str(x))\n",
    "df_test['img_path'] = df_test['Case ID'].apply(lambda x: '../data/Bone Age Test Set/boneage-testing-dataset/'+str(x)) \n",
    "\n",
    "#train_df = train_df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male      6833\n",
      "female    5778\n",
      "Name: gender, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='gender', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#finding out the number of male and female children in the dataset\n",
    "#creating a new column called gender to keep the gender of the child as a string\n",
    "train_df['gender'] = train_df['male'].apply(lambda x: 'male' if x else 'female')\n",
    "print(train_df['gender'].value_counts())\n",
    "sns.countplot(x = train_df['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ctegorical to numeric\n",
    "train_df['gender'].replace(['male', 'female'],[1, 0], inplace=True)\n",
    "df_test['gender'].replace(['M', 'F'],[0, 1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX age: 228 months\n",
      "MIN age: 1 months\n",
      "mean: 127.3207517246848\n",
      "median: 132.0\n",
      "         id  boneage   male  \\\n",
      "0  1377.png      180  False   \n",
      "1  1378.png       12  False   \n",
      "2  1379.png       94  False   \n",
      "3  1380.png      120   True   \n",
      "4  1381.png       82  False   \n",
      "\n",
      "                                            img_path  gender  bone_age_z  \n",
      "0  ../data/Bone Age Training Set/boneage-training...       0    1.279181  \n",
      "1  ../data/Bone Age Training Set/boneage-training...       0   -2.800269  \n",
      "2  ../data/Bone Age Training Set/boneage-training...       0   -0.809109  \n",
      "3  ../data/Bone Age Training Set/boneage-training...       1   -0.177766  \n",
      "4  ../data/Bone Age Training Set/boneage-training...       0   -1.100498  \n"
     ]
    }
   ],
   "source": [
    "#oldest child in the dataset\n",
    "print('MAX age: ' + str(train_df['boneage'].max()) + ' months')\n",
    "\n",
    "#youngest child in the dataset\n",
    "print('MIN age: ' + str(train_df['boneage'].min()) + ' months')\n",
    "\n",
    "#mean age is\n",
    "mean_bone_age = train_df['boneage'].mean()\n",
    "print('mean: ' + str(mean_bone_age))\n",
    "\n",
    "#median bone age\n",
    "print('median: ' +str(train_df['boneage'].median()))\n",
    "\n",
    "#standard deviation of boneage\n",
    "std_bone_age = train_df['boneage'].std()\n",
    "\n",
    "#models perform better when features are normalised to have zero mean and unity standard deviation\n",
    "#using z score for the training\n",
    "train_df['bone_age_z'] = (train_df['boneage'] - mean_bone_age)/(std_bone_age)\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.18202139939618"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_bone_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of children in each age group')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plotting a histogram for bone ages\n",
    "train_df['boneage'].hist(color = 'green')\n",
    "plt.xlabel('Age in months')\n",
    "plt.ylabel('Number of children')\n",
    "plt.title('Number of children in each age group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting train dataframe into traininng and validation dataframes\n",
    "df_train, df_valid = train_test_split(train_df, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/2/2022/mrifat/.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "train_steps = int(np.ceil(len(df_train) / hparams.BATCH_SIZE))\n",
    "val_steps = int(np.ceil(len(df_valid) / hparams.BATCH_SIZE))\n",
    "train_dataset=create_dataset_from_file(df_train[\"img_path\"],df_train['gender'].to_numpy().reshape(-1,1),df_train[hparams.TARGET_VAR].to_numpy().reshape(-1,1))\n",
    "val_dataset=create_dataset_from_file(df_valid[\"img_path\"],df_valid['gender'].to_numpy().reshape(-1,1),df_valid[hparams.TARGET_VAR].to_numpy().reshape(-1,1))\n",
    "test_dataset=create_dataset_from_file(df_test[\"img_path\"],df_test['gender'].to_numpy().reshape(-1,1),df_test[hparams.TARGET_VAR].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mae_in_months(x_p, y_p):\n",
    "    \"\"\"function to return mae in months\"\"\"\n",
    "    return mean_absolute_error(\n",
    "        (std_bone_age * x_p + mean_bone_age), (std_bone_age * y_p + mean_bone_age)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model 1 = baseline, 2 = baseline_attention, 3 = unet, \n",
    "      4 = residual_attention_unet, 5= inception_attention_unet,\n",
    "      6 = cnn_attention_unet\n",
    "\n",
    "submodel for only model 2\n",
    "\n",
    "submodel 1= one_attention_output_attention, 2= one_attention_output_cnn\n",
    "         3= all_attention_output_attention, 4 = all_attention_output_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 256, 256, 16  448         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 256, 256, 16  64         ['conv2d_23[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      multiple             0           ['batch_normalization_23[0][0]', \n",
      "                                                                  'batch_normalization_24[0][0]', \n",
      "                                                                  'batch_normalization_25[0][0]', \n",
      "                                                                  'batch_normalization_26[0][0]', \n",
      "                                                                  'batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 128, 128, 32  4640        ['leaky_re_lu_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 128, 128, 32  128        ['conv2d_24[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 64, 64, 64)   18496       ['leaky_re_lu_4[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 64, 64, 64)  256         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 32, 32, 128)  73856       ['leaky_re_lu_4[2][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 32, 32, 128)  512        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 16, 16, 256)  295168      ['leaky_re_lu_4[3][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 16, 16, 256)  65792       ['leaky_re_lu_4[4][0]']          \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 16, 16, 256)  295168      ['leaky_re_lu_4[3][0]']          \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 16, 16, 256)  0           ['conv2d_28[0][0]',              \n",
      "                                                                  'conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 16, 16, 256)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 16, 16, 1)    257         ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 16, 16, 1)    0           ['conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 32, 32, 1)    0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 32, 32, 128)  0           ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 32, 32, 128)  0           ['lambda[0][0]',                 \n",
      "                                                                  'leaky_re_lu_4[3][0]']          \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 32, 32, 128)  16512       ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 32, 32, 128)  512        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 131072)       0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 16)           2097168     ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            17          ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,870,018\n",
      "Trainable params: 2,868,770\n",
      "Non-trainable params: 1,248\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if hparams.NORMALIZE_OUTPUT == True:\n",
    "    metric = ['mae_in_months']\n",
    "else:\n",
    "    metric = ['mse']\n",
    "\n",
    "if hparams.MODEL_NO == 1:\n",
    "    hparams.MODEL_NAME = \"baseline\"\n",
    "    model = BaselineCnn.baseline_cnn()\n",
    "    \n",
    "elif hparams.MODEL_NO == 2:\n",
    "    hparams.MODEL_NAME = \"baseline_attention_\"+str(hparams.SUB_MODEL_NO)\n",
    "    model =  BaselineCnnAttention.baseline_cnn_attention(hparams.SUB_MODEL_NO)\n",
    "\n",
    "elif hparams.MODEL_NO == 3:\n",
    "    model = Unet.unet()\n",
    "    hparams.MODEL_NAME = \"unet\"\n",
    "\n",
    "elif hparams.MODEL_NO == 4:\n",
    "    model = ResidualAttentionUnet.residual_attention_unet()\n",
    "    hparams.MODEL_NAME = \"residual_attention_unet\" \n",
    "elif hparams.MODEL_NO == 5:\n",
    "    model = InceptionAttentionUnet.inception_attention_unet()\n",
    "    hparams.MODEL_NAME = \"inception_attention_unet\" \n",
    "elif hparams.MODEL_NO == 6:\n",
    "    model = CnnAttentionUnet.cnn_attention_unet()\n",
    "    hparams.MODEL_NAME = \"cnn_attention_unet\" \n",
    "\n",
    "model.compile(loss ='mse', optimizer= 'adam',metrics = metric)\n",
    "#model.compile(loss ='mse', optimizer= 'adam')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:97h2kup9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>lr</td><td>▁</td></tr><tr><td>mse</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>6478.83984</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>11293.20508</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>mse</td><td>11293.20508</td></tr><tr><td>test_mse</td><td>14340.28212</td></tr><tr><td>val_loss</td><td>6478.83984</td></tr><tr><td>val_mse</td><td>6478.83984</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">inception_attention_unet</strong>: <a href=\"https://wandb.ai/hda-project/prod-100/runs/97h2kup9\" target=\"_blank\">https://wandb.ai/hda-project/prod-100/runs/97h2kup9</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230105_201609-97h2kup9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:97h2kup9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5814ef93cd8046b898d25b0dc4074250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0166709825474148, max=1.0))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/server2/2/2022/mrifat/Desktop/Radiograph-Age-Prediction/src/wandb/run-20230105_202445-3omynfeg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hda-project/prod-100/runs/3omynfeg\" target=\"_blank\">unet</a></strong> to <a href=\"https://wandb.ai/hda-project/prod-100\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "        project=hparams.PROJECT_NAME,\n",
    "        entity=\"hda-project\",\n",
    "        name=hparams.MODEL_NAME\n",
    "        # notes=hparams.NOTES\n",
    "    )\n",
    "wandb.config.update(hparams.CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631/631 [==============================] - 2818s 4s/step - loss: 1707.6287 - mse: 1707.6287 - val_loss: 1420.4620 - val_mse: 1420.4620 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "if hparams.GENDER:\n",
    "    hparams.MODEL_NAME = hparams.MODEL_NAME+\"_gender\"\n",
    "    \n",
    "history = train_model(model, train_dataset, val_dataset, train_steps,val_steps)\n",
    "\n",
    "wandb.config.update({\"MODEL_NAME\":hparams.MODEL_NAME})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7fbac3bf7dc0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art = wandb.Artifact(hparams.MODEL_NAME+\"_best_model\", type=\"model\")\n",
    "art.add_file(\"../data/artifact/\" + hparams.MODEL_NAME + \".h5\")\n",
    "wandb.log_artifact(art)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('hda-project/prod-100/unet_best_model:v0', type='model')\n",
    "artifact_dir = artifact.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['gender'].to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('data/artifact/unet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 12s 792ms/step\n"
     ]
    }
   ],
   "source": [
    "test_y = df_test[hparams.TARGET_VAR].to_numpy()\n",
    "pred_y =model.predict(test_dataset)\n",
    "mse_value = mean_squared_error(test_y,pred_y)\n",
    "wandb.log({\"test_mse\":mse_value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = train_df['img_path'].tolist()\n",
    "# y = train_df['boneage'].tolist()\n",
    "#x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "# train_dataset = create_dataset(x_train, y_train,\n",
    "#                                batch_size=hparams.BATCH_SIZE,\n",
    "#                                shuffle=True,\n",
    "#                                cache_file=hparams.TRAIN_CACHE_PATH)\n",
    "\n",
    "# val_dataset = create_dataset(x_val, y_val,\n",
    "#                               batch_size=hparams.BATCH_SIZE,\n",
    "#                               shuffle=False,\n",
    "#                               cache_file=hparams.VAL_CACHE_PATH)\n",
    "\n",
    "# train_steps = int(np.ceil(len(x_train) / hparams.BATCH_SIZE))\n",
    "# val_steps = int(np.ceil(len(x_val) / hparams.BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.save(\"../data/artifact/\" + hparams.MODEL_NAME + \".h5\")\n",
    "# art = wandb.Artifact(\"best_model\", type=\"model\")\n",
    "# art.add_file(\"../data/artifact/\" + hparams.MODEL_NAME + \".h5\")\n",
    "# wandb.log_artifact(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = AutoEncoder.auto_encoder()\n",
    "# model.compile(loss ='mse', optimizer= 'adam',metrics = ['mse'])\n",
    "# #model.compile(loss ='mse', optimizer= 'adam')\n",
    "# model.summary()\n",
    "# history = train_model(model, train_dataset, val_dataset,train_steps,val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking GPU Status"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")\n",
    "\n",
    "https://github.com/philipperemy/keras-attention-mechanism\n",
    "https://towardsdatascience.com/a-detailed-explanation-of-the-attention-u-net-b371a5590831\n",
    "https://github.com/bnsreenu/python_for_microscopists\n",
    "https://github.com/bnsreenu/python_for_microscopists/blob/master/076-077-078-Unet_nuclei_tutorial.py\n",
    "https://github.com/robinvvinod/unet\n",
    "https://www.datacamp.com/tutorial/autoencoder-classifier-python\n",
    "https://www.kaggle.com/code/kmader/attention-on-pretrained-vgg16-for-bone-age\n",
    "https://stackoverflow.com/questions/52582275/tf-data-with-multiple-inputs-outputs-in-keras\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "# TF_FORCE_GPU_ALLOW_GROWTH=true\n",
    "gpu_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.image as mpimg\n",
    "# import matplotlib.pyplot as plt\n",
    "# img = mpimg.imread('../data/Bone Age Training Set/boneage-training-dataset/1381.png')\n",
    "# plt.imshow(img)\n",
    "# print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if hparams.GENDER:\n",
    "    train_generator.reset()\n",
    "    train_x,train_y = next(train_generator)\n",
    "\n",
    "    for i in range((math.ceil(len(df_train)/train_batch_size))-1):\n",
    "        tmp_x,tmp_y = next(train_generator)\n",
    "        train_x = np.concatenate((train_x,tmp_x),axis=0)\n",
    "        train_y = np.concatenate((train_y,tmp_y),axis=0)\n",
    "        print(\"in train\")\n",
    "    \n",
    "    val_generator.reset()\n",
    "    val_x,val_y = next(val_generator)\n",
    "    print(\"done\")\n",
    "    for i in range((math.ceil(len(df_valid)/val_batch_size))-1):\n",
    "        tmp_x,tmp_y = next(val_generator)\n",
    "        val_x = np.concatenate((val_x,tmp_x),axis=0)\n",
    "        val_y = np.concatenate((val_y,tmp_y),axis=0)\n",
    "\n",
    "    test_generator.reset()\n",
    "    test_x = next(test_generator)\n",
    "\n",
    "    for i in range((math.ceil(len(df_test)/test_batch_size))-1):\n",
    "        tmp_x = next(test_generator)\n",
    "        test_x = np.concatenate((test_x,tmp_x),axis=0)\n",
    "        \n",
    "\n",
    "    gend_train_x =(df_train['gender'].to_numpy()).reshape(-1,1)\n",
    "    gend_val_x =(df_valid['gender'].to_numpy()).reshape(-1,1)\n",
    "    gend_test_x =(df_test['gender'].to_numpy()).reshape(-1,1)\n",
    "    hparams.MODEL_NAME = hparams.MODEL_NAME+\"_gender\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3omynfeg) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d202e901ba1b41a4a0bbd04c5cb9a0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.305930…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>lr</td><td>▁</td></tr><tr><td>mse</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1420.46204</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1707.62866</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>mse</td><td>1707.62866</td></tr><tr><td>test_mse</td><td>1887.17854</td></tr><tr><td>val_loss</td><td>1420.46204</td></tr><tr><td>val_mse</td><td>1420.46204</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">unet</strong>: <a href=\"https://wandb.ai/hda-project/prod-100/runs/3omynfeg\" target=\"_blank\">https://wandb.ai/hda-project/prod-100/runs/3omynfeg</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230105_202445-3omynfeg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3omynfeg). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401aa357c08d43018e5113e8e5c182ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666901713081946, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/server2/2/2022/mrifat/Desktop/Radiograph-Age-Prediction/src/wandb/run-20230105_211213-30ec1eg6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hda-project/Radiograph-Age-Prediction-src/runs/30ec1eg6\" target=\"_blank\">wobbly-mountain-1</a></strong> to <a href=\"https://wandb.ai/hda-project/Radiograph-Age-Prediction-src\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/hda-project/Radiograph-Age-Prediction-src/runs/30ec1eg6?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fbac1cb41f0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = hparams.CONFIG\n",
    "config[\"project\"] = hparams.PROJECT_NAME\n",
    "config[\"entity\"] = \"hda-project\"\n",
    "config[\"name\"] = hparams.MODEL_NAME\n",
    "\n",
    "wandb.init(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.metrics import mean_absolute_error\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import wandb\n",
    "from hparams import *\n",
    "from models import *\n",
    "from utils import create_dataset_from_file, set_seeds, train_model\n",
    "\n",
    "set_seeds(42)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # 1 for run in gpu -1 for run in cpu\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# os.environ['TF_GPU_ALLOCATOR'] ='cuda_malloc_async'\n",
    "\n",
    "\n",
    "# loading dataframes\n",
    "df_train = pd.read_csv(\"data/Bone Age Training Set/train.csv\")\n",
    "df_test = pd.read_excel(\"data/Bone Age Test Set/test.xlsx\")\n",
    "df_valid = pd.read_csv(\"data/Bone Age Validation Set/Validation Dataset.csv\")\n",
    "\n",
    "\n",
    "# appending file extension to id column for both training and testing dataframes\n",
    "df_train[\"id\"] = df_train[\"id\"].apply(lambda x: str(x) + \".png\")\n",
    "df_test[\"Case ID\"] = df_test[\"Case ID\"].apply(lambda x: str(x) + \".png\")\n",
    "df_valid[\"Image ID\"] = df_valid[\"Image ID\"].apply(lambda x: str(x) + \".png\")\n",
    "df_test.rename(\n",
    "    columns={\"Ground truth bone age (months)\": \"boneage\", \"Sex\": \"gender\"}, inplace=True\n",
    ")\n",
    "\n",
    "df_valid.rename(\n",
    "    columns={\"Bone Age (months)\": \"boneage\", \"male\": \"gender\"}, inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "df_train[\"img_path\"] = df_train[\"id\"].apply(\n",
    "    lambda x: \"data/Bone Age Training Set/boneage-training-dataset/\" + str(x)\n",
    ")\n",
    "df_test[\"img_path\"] = df_test[\"Case ID\"].apply(\n",
    "    lambda x: \"data/Bone Age Test Set/boneage-testing-dataset/\" + str(x)\n",
    ")\n",
    "\n",
    "df_valid[\"img_path\"] = df_valid[\"Image ID\"].apply(\n",
    "    lambda x: \"data/Bone Age Validation Set/boneage-validation-dataset/\" + str(x)\n",
    ")\n",
    "\n",
    "\n",
    "df_train[\"gender\"] = df_train[\"male\"].apply(lambda x: \"male\" if x else \"female\")\n",
    "df_train[\"gender\"].replace([\"male\", \"female\"], [1, 0], inplace=True)\n",
    "df_test[\"gender\"].replace([\"M\", \"F\"], [1, 0], inplace=True)\n",
    "df_valid[\"gender\"].replace([True, False], [1, 0], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# mean age is\n",
    "mean_bone_age = df_train[\"boneage\"].mean()\n",
    "# standard deviation of boneage\n",
    "std_bone_age = df_train[\"boneage\"].std()\n",
    "\n",
    "# using z score for the training\n",
    "df_train[\"bone_age_z\"] = (df_train[\"boneage\"] - mean_bone_age) / (std_bone_age)\n",
    "df_test[\"bone_age_z\"] = (df_test[\"boneage\"] - mean_bone_age) / (std_bone_age)\n",
    "df_valid[\"bone_age_z\"] = (df_valid[\"boneage\"] - mean_bone_age) / (std_bone_age)\n",
    "\n",
    "# splitting train dataframe into traininng and validation dataframes\n",
    "# df_train, df_valid = train_test_split(train_df, test_size=0.3, random_state=0)\n",
    "\n",
    "df_train = df_train.head(100)\n",
    "\n",
    "\n",
    "train_steps = int(np.ceil(len(df_train) / hparams.BATCH_SIZE))\n",
    "val_steps = int(np.ceil(len(df_valid) / hparams.BATCH_SIZE))\n",
    "train_dataset = create_dataset_from_file(\n",
    "    df_train[\"img_path\"],\n",
    "    df_train[\"gender\"].to_numpy().reshape(-1, 1),\n",
    "    df_train[hparams.TARGET_VAR].to_numpy().reshape(-1, 1),\n",
    ")\n",
    "val_dataset = create_dataset_from_file(\n",
    "    df_valid[\"img_path\"],\n",
    "    df_valid[\"gender\"].to_numpy().reshape(-1, 1),\n",
    "    df_valid[hparams.TARGET_VAR].to_numpy().reshape(-1, 1),\n",
    ")\n",
    "test_dataset = create_dataset_from_file(\n",
    "    df_test[\"img_path\"],\n",
    "    df_test[\"gender\"].to_numpy().reshape(-1, 1),\n",
    "    df_test[hparams.TARGET_VAR].to_numpy().reshape(-1, 1),\n",
    ")\n",
    "\n",
    "\n",
    "def mae_in_months(x_p, y_p):\n",
    "    \"\"\"function to return mae in months\"\"\"\n",
    "    if hparams.NORMALIZE_OUTPUT == True:\n",
    "        return mean_absolute_error(\n",
    "            (std_bone_age * x_p + mean_bone_age), (std_bone_age * y_p + mean_bone_age))\n",
    "    else:\n",
    "        return mean_absolute_error(x_p,y_p)\n",
    "    \n",
    "\n",
    "# for i in [1, [2, 1], [2, 2], [2, 3], [2, 4], 3, 4, 6]:\n",
    "    # for i in [[2, 3], [2, 4], 3, 4, 6]:\n",
    "    # MODEL_NO = i[0]\n",
    "for i in [3]:\n",
    "    try:\n",
    "        if type(i) == list:\n",
    "            hparams.MODEL_NO = i[0]\n",
    "            hparams.SUB_MODEL_NO = i[1]\n",
    "        else:\n",
    "            hparams.MODEL_NO = i\n",
    "\n",
    "\n",
    "        if hparams.MODEL_NO == 1:\n",
    "            hparams.MODEL_NAME = \"baseline\"\n",
    "            model = BaselineCnn.baseline_cnn()\n",
    "\n",
    "        elif hparams.MODEL_NO == 2:\n",
    "            hparams.MODEL_NAME = \"baseline_attention_\" + str(hparams.SUB_MODEL_NO)\n",
    "            model = BaselineCnnAttention.baseline_cnn_attention(hparams.SUB_MODEL_NO)\n",
    "\n",
    "        elif hparams.MODEL_NO == 3:\n",
    "            model = Unet.unet()\n",
    "            hparams.MODEL_NAME = \"unet\"\n",
    "\n",
    "        elif hparams.MODEL_NO == 4:\n",
    "            model = ResidualAttentionUnet.residual_attention_unet()\n",
    "            hparams.MODEL_NAME = \"residual_attention_unet\"\n",
    "        elif hparams.MODEL_NO == 5:\n",
    "            model = InceptionAttentionUnet.inception_attention_unet()\n",
    "            hparams.MODEL_NAME = \"inception_attention_unet\"\n",
    "        elif hparams.MODEL_NO == 6:\n",
    "            model = CnnAttentionUnet.cnn_attention_unet()\n",
    "            hparams.MODEL_NAME = \"cnn_attention_unet\"\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(hparams.START_LR)\n",
    "        model.compile(loss=\"mse\", optimizer=optimizer, metrics=[mae_in_months])\n",
    "        wandb.init(\n",
    "            project=hparams.PROJECT_NAME,\n",
    "            entity=\"hda-project\",\n",
    "            name=hparams.MODEL_NAME\n",
    "            # notes=hparams.NOTES\n",
    "        )\n",
    "        wandb.config.update(hparams.CONFIG)\n",
    "\n",
    "        if hparams.GENDER:\n",
    "            hparams.MODEL_NAME = hparams.MODEL_NAME + \"_gender\"\n",
    "\n",
    "        history = train_model(model, train_dataset, val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "pred_y= np.array([1,6,3,8])\n",
    "\n",
    "test_y= np.array([1,2,3,4])\n",
    "mae_value = sklearn.metrics.mean_absolute_error(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrifat1493\u001b[0m (\u001b[33mhda-project\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "wandb: ERROR Failed to sample metric: Not Supported\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rifat/Desktop/Radiograph-Age-Prediction/src/wandb/run-20230212_222933-b4dom33s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hda-project/hda-final/runs/b4dom33s\" target=\"_blank\">Inception V4</a></strong> to <a href=\"https://wandb.ai/hda-project/hda-final\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/hda-project/hda-final/runs/b4dom33s?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f5bc593f190>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(\n",
    "    project=\"hda-final\",\n",
    "    entity=\"hda-project\",\n",
    "    name=\"Inception V4\",\n",
    "    id=\"b4dom33s\"\n",
    "    # notes=hparams.NOTES\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"test_mae_in_months\": 29.078})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_mae_in_months</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_mae_in_months</td><td>29.078</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">Inception V4</strong>: <a href=\"https://wandb.ai/hda-project/hda-final/runs/b4dom33s\" target=\"_blank\">https://wandb.ai/hda-project/hda-final/runs/b4dom33s</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230212_222933-b4dom33s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b58e8d2897631be50599cb2475829bc7f4f92a7dfee912534f9645fab183932d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
